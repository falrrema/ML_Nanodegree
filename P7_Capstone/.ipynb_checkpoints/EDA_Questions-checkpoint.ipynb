{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "### <font color='salmon'>Project: Quora Insincere Questions Classification Project</font> \n",
    "\n",
    "The following notebook will explore the data set provided in the quora kaggle competition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string as st\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "%matplotlib inline\n",
    "\n",
    "# Loading helper functions\n",
    "import helper as h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='firebrick'>1. Basic Statistics </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>959000</th>\n",
       "      <td>bbe41d257f0b65c1e524</td>\n",
       "      <td>How do you know if the clutch in the car is gone?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748772</th>\n",
       "      <td>92b1b063939fb02b351e</td>\n",
       "      <td>How do you deal with anger outburst within a r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866745</th>\n",
       "      <td>a9d263eea7cfba0030b0</td>\n",
       "      <td>Is Acela Express really worth to take?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86613</th>\n",
       "      <td>10f9ea7b9eab8c1eb193</td>\n",
       "      <td>What are the thermal properties of alumina? Wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244306</th>\n",
       "      <td>2fc86896a7ba3fff9082</td>\n",
       "      <td>Can any dentists on Quora advise if Nancy Pelo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         qid  \\\n",
       "959000  bbe41d257f0b65c1e524   \n",
       "748772  92b1b063939fb02b351e   \n",
       "866745  a9d263eea7cfba0030b0   \n",
       "86613   10f9ea7b9eab8c1eb193   \n",
       "244306  2fc86896a7ba3fff9082   \n",
       "\n",
       "                                            question_text  target  \n",
       "959000  How do you know if the clutch in the car is gone?       0  \n",
       "748772  How do you deal with anger outburst within a r...       0  \n",
       "866745             Is Acela Express really worth to take?       0  \n",
       "86613   What are the thermal properties of alumina? Wh...       0  \n",
       "244306  Can any dentists on Quora advise if Nancy Pelo...       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "tqdm.pandas()\n",
    "train_set = pd.read_csv('Data/train.csv', encoding = 'latin1')\n",
    "train_set.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048575, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data consists of 3 columns, the question id (qid), the questions text (question_text) and target column (target). The is a total 1048575 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strong class imbalance. There are 64774 of insincere question that representthe 6.2% of the data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target variable count\n",
    "ax = sns.countplot(y=\"target\", data=train_set, palette=\"Set1\") # strong class imbalance \n",
    "cnts = train_set.target.value_counts()\n",
    "print(\"Strong class imbalance. \" \n",
    "      \"There are {} of insincere question that represent\"\n",
    "      \"the {}% of the data\".format(cnts[1], round(cnts[1]/sum(cnts)*100, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='firebrick'>2. Text Cleaning and preprocessing </font> \n",
    "\n",
    "Text is the most unstructured form of all the available data, thus various types of noise are present in it. It's necessary to clean, standarise and normalize to make it readily analyzable. I will perform the following text preprocessing pipeline:\n",
    "\n",
    "* Noise Removal: stopwords and punctuations mark.\n",
    "* Lexicon Normalization: Mainly lemmatization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How Otto von Guericke used Magdeburg hemispheres?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.remove_stopwords(train_set.question_text[3], stop_words=STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1048575/1048575 [00:01<00:00, 718732.19it/s]\n",
      "100%|██████████| 1048575/1048575 [00:04<00:00, 250598.60it/s]\n",
      "100%|██████████| 1048575/1048575 [00:02<00:00, 363726.20it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set['qt_cleaned'] = train_set.question_text.progress_apply(lambda t: t.lower())\n",
    "train_set['qt_cleaned'] = train_set.qt_cleaned.progress_apply(lambda t: h.remove_stopwords(t,stop_words=STOPWORDS))\n",
    "translator = str.maketrans('', '', st.punctuation)\n",
    "train_set['qt_cleaned'] = train_set.qt_cleaned.progress_apply(lambda t: t.translate(translator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(str(train_set.qt_cleaned[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['otto', 'von', 'guericke', 'use', 'magdeburg', 'hemispheres']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_words = [wnl.lemmatize(word, pos='v') for word in words] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# WordCloud of sincere questions\n",
    "sincere_questions = train_set[train_set.target == 0].question_text\n",
    "insincere_questions = train_set[train_set.target == 1].question_text\n",
    "h.plot_wordcloud(sincere_questions, max_words=50, \n",
    "                 max_font_size=100, stop_words = STOPWORDS, \n",
    "                 figure_size=(8,10), scale = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.plot_wordcloud(insincere_questions, max_words=50, \n",
    "                 max_font_size=50, stop_words = STOPWORDS, \n",
    "                 figure_size=(8,10), scale = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the word clouds we see that sincere questions have more words related to verbs that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wnl.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
